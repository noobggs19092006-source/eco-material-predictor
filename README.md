# ðŸŒ¿ Eco-Material Property Predictor

A machine-learning pipeline that predicts **10 material properties** of eco-friendly engineering plastics and alloys â€” no physical testing required.

**Predicted properties (Held-out Test RÂ²):**
| Property | Unit | Polymer RÂ² | Alloy RÂ² |
|---|---|---|---|
| Glass Transition Temperature (Tg) | Â°C | **0.98** | **0.96** |
| Tensile Strength | MPa | **0.93** | **0.96** |
| Young's Modulus | GPa | **0.90** | **0.99** |
| Density | g/cmÂ³ | **0.85** | **0.99** |
| Thermal Conductivity | W/mÂ·K | **0.93** | **0.97** |
| Electrical Conductivity | logâ‚â‚€ S/m | **0.92** | **0.96** |
| Elongation at Break | % | **0.94** | **0.96** |
| Dielectric Constant | â€” | **0.95** | **0.95** |
| Water Absorption | % | **0.95** | **0.97** |
| Oâ‚‚ Permeability | Barrers | **0.97** | **0.97** |

**Materials covered:** PLA, PHA, PHB, PBS, PEF, Bio-PA, Cellulose derivatives, Lignin-based polymers, Chitosan, Starch blends, eco-epoxies, metal alloys, and 160+ more.

---

## ðŸš€ Mode A â€” Hackathon / Fresh Start (For Judges & Visitors)

> Use this if you're running the project **for the first time** on a new machine.
> This builds everything from scratch: environment â†’ dataset â†’ training â†’ demo.

```bash
# 1. Clone and enter the project
git clone <repo-url>
cd eco-material-predictor

# 2. Create the virtual environment and install all dependencies (~2 min)
bash setup.sh

# 3. Activate the environment
source venv/bin/activate

# 4. Generate the dataset with QSPR formulas + realistic noise (~5 sec)
python scripts/perfect_dataset.py

# 5. Train both polymer and alloy ensemble models (~5â€“10 min)
make train

# 6. Generate evaluation report + 5 publication-quality graphs
make evaluate

# 7. Launch the Interactive Web Dashboard (React + FastAPI)
make app
# â†’ API at http://localhost:8000  |  Frontend at http://localhost:5173
# Features 3D Parallax Liquid-Glass UI, Dynamic Polymer/Alloy Radar Charts, 
# and a True Multivariate AI Recommender for bio-based materials.

# 8. (Optional) Launch the barebones interactive CLI predictor
make predict

# 9. (Optional) Run the full test suite â€” all 27 tests should pass
make test
```

---

## âš¡ Mode B â€” Developer / Quick Resume (For the Author)

> Use this if the **venv already exists** and you just want to retrain or demo.

```bash
# Activate the environment
source venv/bin/activate

# Option 1: Full retrain from scratch
make clean
python scripts/perfect_dataset.py
make train
make evaluate

# Option 2: Just re-evaluate (model already trained)
make evaluate

# Option 3: Launch the Interactive Web Dashboard
make app
# â†’ API at http://localhost:8000  |  Frontend at http://localhost:5173
# Features 3D Parallax Liquid-Glass UI, Dynamic Polymer/Alloy Radar Charts, 
# and a True Multivariate AI Recommender for bio-based materials.

# Option 4: Run the CLI predictor immediately
make predict

# Option 5: Run tests
make test
```

---

## ðŸ“ Project Structure

```
eco-material-predictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/materials_dataset.csv       â† curated 285-row dataset
â”‚   â””â”€â”€ processed/                      â† auto-generated splits (after make train)
â”‚       â”œâ”€â”€ features_train.csv          â† 70% (199 rows)
â”‚       â”œâ”€â”€ features_val.csv            â† 10% (29 rows)
â”‚       â””â”€â”€ features_test.csv           â† 20% (57 rows) â€” held-out final eval
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ material_predictor.pkl          â† stacked ensemble (polymer + alloy models)
â”‚   â””â”€â”€ scaler.pkl                      â† fitted StandardScaler
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ evaluation_report_polymers.txt  â† MAE / RMSE / RÂ² per target (Polymers)
â”‚   â”œâ”€â”€ evaluation_report_alloys.txt    â† MAE / RMSE / RÂ² per target (Alloys)
â”‚   â”œâ”€â”€ 01_actual_vs_predicted_*.png    â† scatter plots (separate for poly/alloy)
â”‚   â”œâ”€â”€ 02_feature_importance_heatmap.png
â”‚   â”œâ”€â”€ 03_property_correlation_matrix.png
â”‚   â”œâ”€â”€ 04_eco_score_vs_properties.png
â”‚   â””â”€â”€ 05_residual_distributions_*.png â† residual distributions
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ perfect_dataset.py              â† QSPR dataset generator (run before train)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py                    â† feature engineering + 70/10/20 split
â”‚   â”œâ”€â”€ train.py                        â† stacked ensemble training (polymer + alloy)
â”‚   â”œâ”€â”€ evaluate.py                     â† metrics + 5 publication-quality graphs
â”‚   â”œâ”€â”€ predict.py                      â† programmatic inference API
â”‚   â”œâ”€â”€ cli.py                          â† interactive terminal predictor
â”‚   â”œâ”€â”€ api.py                          â† FastAPI backend (REST endpoints)
â”‚   â”œâ”€â”€ recommend.py                    â† Green Alternative Recommender engine
â”‚   â””â”€â”€ generate_pdb.py                 â† PDB file generator for VMD visualization
â”œâ”€â”€ frontend/                           â† React + Vite web app
â”‚   â”œâ”€â”€ src/App.jsx                     â† main UI (sliders, radar chart, predictor)
â”‚   â”œâ”€â”€ src/index.css                   â† liquid-glass biopunk CSS
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py                â† 27 pytest unit tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.sh                            â† Linux one-shot installer
â”œâ”€â”€ Makefile                            â† all shortcut commands
â””â”€â”€ README.md
```

---

## ðŸ¤– Model Architecture

```
285 rows â†’ 70% Train (199) / 10% Val (29) / 20% Test (57)
                                                   â†‘ completely held-out for RÂ²

Input Features (10) per material class:
       â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
  RF       XGB       â† base learners (RandomizedSearchCV hyperparameter tuning)
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚
    Ridge            â† meta-learner (stacking, trained on OOF predictions)
       â”‚
  10 Predictions + Confidence (Â±std from RF ensemble)

Two separate ensembles: POLYMER model (100 samples) + ALLOY model (99 samples)
```

**Features used:**
| Feature | Description |
|---|---|
| `repeat_unit_MW` | Molecular weight of polymer repeat unit (g/mol) |
| `backbone_flexibility` | Chain stiffness (0 = rigid, 1 = flexible) |
| `polarity_index` | Polarity (0 = nonpolar, 3 = highly polar) |
| `hydrogen_bond_capacity` | H-bond strength (0â€“5) |
| `aromatic_content` | Fraction of aromatic carbons (0â€“1) |
| `crystallinity_tendency` | Crystallinity (0 = amorphous, 1 = crystalline) |
| `eco_score` | Bio-based sustainability (0 = petroleum, 1 = bio-based) |
| `is_alloy` | Binary: 0 = polymer, 1 = metal alloy |
| `mw_flexibility` | Interaction: MW Ã— flexibility |
| `polar_hbond` | Interaction: polarity Ã— H-bond capacity |

---

## ðŸ§ª Dataset

**285 materials** curated from:
- Published QSPR (Quantitative Structure-Property Relationship) literature
- Matmatch and CAMPUS Plastics databases
- Peer-reviewed polymer physics data (Fox-Flory, Gibbs-DiMarzio models)
- Augmented with diverse synthetic metal alloy grades (Fe, Ti, Al, Mg, Cu)

Properties generated via `scripts/perfect_dataset.py` using scientifically-grounded QSPR formulas + **2% realistic measurement noise** (simulates actual lab uncertainty), then split 70/10/20 to ensure honest, reproducible RÂ² evaluation with **zero data leakage**.

---

## ï¿½ VMD Visualization Tips

The generated `.pdb` files from `make predict` can be visualized in VMD. By default, VMD uses a simple "Lines" representation. For a professional, high-quality look:
1. Open VMD and load your `.pdb` file.
2. Go to **Graphics > Representations**.
3. Change **Drawing Method** from `Lines` to `CPK` or `Licorice`.
4. (Optional) Change **Coloring Method** to `Name` to color by element (O = red, C = cyan, etc.).
5. (Optional) Go to **Display > Display Settings** and set **Axes** to `Off` to hide the XYZ arrows for a cleaner screenshot.

---

## ï¿½ðŸ“Š Programmatic API

```python
from src.predict import predict

result = predict({
    "repeat_unit_MW":         72.0,   # PLA
    "backbone_flexibility":   0.40,
    "polarity_index":         2,
    "hydrogen_bond_capacity": 2,
    "aromatic_content":       0.0,
    "crystallinity_tendency": 0.35,
    "eco_score":              1.0,
    "is_alloy":               0,
})

print(result["predictions"])
# {'Tg_celsius': 62.4, 'tensile_strength_MPa': 87.4, ..., 'oxygen_permeability_barrer': 17.1}
print(result["confidence"])
# {'Tg_celsius': 3.4, ...}  # Â±std from RF ensemble
```

---

## ðŸ›  Commands Reference

| Command | Action |
|---|---|
| `bash setup.sh` | Create venv + install all Python deps |
| `python scripts/perfect_dataset.py` | Generate dataset (run once before training) |
| `make train` | Prepare data + train stacked ensemble |
| `make evaluate` | Evaluate on test set + save 5 plots to `results/` |
| `make app` | Launch React Web Dashboard + FastAPI backend |
| `make predict` | Launch interactive CLI (terminal only) |
| `make test` | Run pytest suite (27 tests) |
| `make clean` | Remove generated models and result files |

---

## License

MIT â€” free to use, modify, and build upon.
